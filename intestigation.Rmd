---
title: "IDS investigation worksheet"
author: "by Team-Name: User1, User2, User3, User4 & User5"
date: "`r Sys.Date()`"
output: html_document
---

**Note:** You can use this file as you 'working document' where you can try out various investigation ideas and keep notes about your findings. How you use and structure this file is up to you. It is recommended that you keep notes about what you are investigating and what you find as this will make the process of creating your presentation and report easier. Please note that you _do not_ need to submit this file as part of your group project.



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-lib, message = FALSE}
library(tidyverse)
library(tidymodels)
library(openintro)
library(readr)
laptop_data_cleaned <- read_csv("laptop_data_cleaned.csv")
glimpse(laptop_data_cleaned)

## Data pre-processing
# Test the number of NA in data set
colSums(is.na(laptop_data_cleaned))
# Keep the data for sum of HDD and SSD greater than 128
laptop_data_cleaned <- filter(laptop_data_cleaned, HDD+SSD >= 128)
# Count different texts for different variables
count(laptop_data_cleaned, Company)
count(laptop_data_cleaned, TypeName)
count(laptop_data_cleaned, Cpu_brand)
count(laptop_data_cleaned, Gpu_brand)
count(laptop_data_cleaned, Os)
# Change type of data from characters to doubles by 'as.factor'
# Give them a 'weight'
laptop_data_cleaned <- laptop_data_cleaned %>% 
  mutate(Company = as.factor(Company),
         TypeName = as.factor(TypeName),
         Cpu_brand = as.factor(Cpu_brand),
         Gpu_brand = as.factor(Gpu_brand),
         Os = as.factor(Os)
         )

## Split training and testing data sets
# Fix random numbers by setting the seed 
set.seed(1365)
# Put 80% of the data into the training set 
laptop_split <- initial_split(laptop_data_cleaned, prop = 0.80)
# Create data frames for the two sets:
train_data <- training(laptop_split)
test_data  <- testing(laptop_split)

laptop_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Price ~ ., data = train_data)



tidy(laptop_fit)
glance(laptop_fit)$adj.r.squared 

```


```{r load-data}
# load your data 




```


